# 머신 러닝 기본 개념
---
## 0️⃣ 함수

프로그래밍에서 함수는 어떤 **입력(Input)** 을 넣으면, 정해진 연산을 통해 **출력(Output)** 을 반환하는 구조이다.  마치 자판기에 돈을 넣으면 음료가 나오는 것처럼, 함수는 입력을 받아 처리하고 결과를 제공한다.  

예를 들어, `f(x) = x + 1`이라는 함수에 `3`을 넣으면 결과는 `4`가 된다.  
이 개념은 인공지능을 이해하는 데 매우 중요한 기초 개념이 된다.  
인공지능 모델 또한 결국 **하나의 함수처럼 작동**하며, 데이터를 입력받아 예측 또는 분류 결과를 출력한다.

![[Pasted image 20250706195933.png]]

아래 그림은 하나의 함수 구조를 시각적으로 나타낸 것이다.  

왼쪽 박스는 "입력(Input)"을 받아 내부 연산을 통해 "출력(Output)"을 생성하는 구조이다.

- 입력값 `3`이 함수 내부로 들어가고, 
- 출력값 `8`이 결과로 나오고 있다.

이때 **내부에서 어떤 연산이 수행되었는가?** 를 추측할 수 있다.  
`3 → 8`이 되었다면, 내부 연산은 `+5`일 가능성이 크다.

이는 수학적으로  f(x) = x + θ 와 같이 표현할 수 있다.
여기서 `θ`는 **함수 내부의 가중치(또는 파라미터)** 로 생각할 수 있다.

## 수학적 표현과 머신러닝의 의미

그림의 오른쪽 수식을 통해 함수의 수학적 표현은 아래와 같다.

- fθ : ℝ → ℝ  
- x → x + θ

이 수식의 의미는 다음과 같다.
- 함수 `fθ`는 실수 값(ℝ）을 입력으로 받아, 또 다른 실수 값（ℝ‘）을 출력하는 계산 과정을 나타낸다.
- 입력값 `x`가 주어지면, 결과값은 `x + θ`로 계산된다.
- `θ`는 학습 가능한 파라미터이며, 머신러닝 모델이 학습 과정에서 조정하게 된다.

| 수식 구성 요소      | 의미                                 |
| ------------- | ---------------------------------- |
| `x`           | 입력(Input), 독립변수, 인풋 피처(Features)   |
| `x + θ`       | 출력(Output), 종속변수, 추론값(Predictions) |
| `f(x)` 또는 `ŷ` | 모델이 예측한 출력값                        |

---
# 1️⃣ 인공지능, 머신러닝, 딥러닝의 개념
## 인공지능(AI)

인공지능은 인간의 **학습**, **추론**, **지각** 능력을 컴퓨터가 수행할 수 있도록 만든 기술이다.  
즉, 컴퓨터가 데이터를 받아들이고, 그 안의 패턴을 파악하거나 판단을 내릴 수 있도록 설계된 시스템이다.  

인공지능은 다양한 분야에서 활용된다. 
- 유튜브 영상 추천
- 자율주행 자동차
- 음성 인식 및 번역
- 이상 거래 탐지
- 질병 진단 등

---
## 머신러닝(ML)

머신러닝은 인공지능(AI)의 하위 개념으로, 사람이 일일이 프로그램을 작성하지 않아도 **컴퓨터가 데이터로부터 스스로 규칙이나 패턴을 학습**하여 새로운 입력에 대해 결과를 예측하거나 분류할 수 있도록 만든 기술이다. 전통적인 프로그래밍은 사람이 문제 해결 과정을 코드로 작성하지만, 머신러닝에서는 알고리즘이 데이터에서 스스로 관계를 찾아낸다.

특히 머신러닝에서는 사람이 **직접 특징(Feature)** 을 정의하고, 그 특징과 정답(Label)의 관계를 모델이 학습하는 구조이다.  예를 들어 고양이 이미지를 분류하기 위해 "귀 모양", "눈의 위치", "털의 색" 등을 사람이 미리 정한 후, 모델이 그것을 기준으로 학습한다.

머신러닝은 다음과 같은 작업에 활용된다.
- 이미지 분류
- 텍스트 분류
- 스팸 필터링
- 추천 시스템 등

---
## 딥러닝(DL)

딥러닝은 머신러닝의 하위 개념으로, **인공신경망(Neural Network)** 을 기반으로 한 머신러닝의 한 분야이다. 딥러닝에서는 사람이 별도로 특징을 정의하지 않아도 된다. 모델이 데이터의 저수준부터 고수준까지의 **복잡한 특징을 스스로 추출**하고, 입력에서 출력으로 바로 연결되는 **매핑 관계를 학습**한다.

딥러닝은 다음과 같은 작업에 활용된다.
- 이미지 인식
- 음성 인식
- 자연어 처리 (번역, 요약, 챗봇 등)
- 생성 모델 (예: 그림, 음악, 텍스트 생성)
---
## 인공지능과 머신러닝 그리고 딥러닝


![[Pasted image 20250706175645.png]]

위 그림은 인공지능(AI), 머신러닝(ML), 딥러닝(DL)의 관계를 시각적으로 나타낸 것이다.

- **가장 바깥의 인공지능(AI)** 은 인간 지능을 모방하는 모든 기술을 포함한다.
- 그 안에 **데이터로부터 패턴을 학습하는 머신러닝(ML)** 이 포함된다.
- 머신러닝의 하위에는, **신경망을 통해 특징 추출과 판단을 모두 자동화하는 딥러닝(DL)** 이 위치한다.

즉, AI ⊃ ML ⊃ DL의 관계로 구성되며, 기술이 고도화될수록 **사람의 개입이 줄어들고**, 모델이 스스로 더 많은 것을 학습하게 된다.

| 범주 | 주된 방식 | 특징 추출 | 예 |
|------|------------|------------|----|
| 인공지능 | 모든 인간 지능 모사 | 수동/자동 혼합 | 자율주행, 챗봇 등 |
| 머신러닝 | 데이터 기반 학습 | 사람이 특징 정의 | 스팸 필터, 추천 시스템 |
| 딥러닝 | 신경망 기반 자동 학습 | 기계가 직접 추출 | 이미지 분류, 음성 인식 |

---
## 2️⃣학습(Learning)이란?

머신러닝과 딥러닝의 중심에는 **학습(Learning)** 이라는 개념이 있다.  
학습이란, **데이터로부터 규칙을 찾아내어 성능을 향상시키는 과정**을 의미한다.  
즉, 입력과 출력(정답)을 반복적으로 관찰하면서, 입력 → 출력 사이의 관계를 점점 더 정확하게 예측할 수 있도록 하는 과정이다.

머신러닝의 학습 방식은 **사용 가능한 데이터의 특성과 정답(Label)의 유무** 에 따라 다음과 같이 나뉜다.

---
## 학습 유형별 설명

### 1) 지도학습 (Supervised Learning)

- **입력(Input)** 과 그에 대한 **정답(Label)** 이 함께 주어지는 데이터로 학습한다.
- 목표는 주어진 입력에 대해 **정확한 출력을 예측**하는 모델을 만드는 것이다.
- **정답이 명확하게 존재**하는 문제에 적합하다.
- 주로 **분류(Classification)**, **회귀(Regression)** 문제에서 사용된다. 분류와 회귀는 6️⃣ 챕터에서 다시 설명할 예정이다.
- **예시**:  
  - 이미지에서 고양이/강아지를 분류  
  - 집의 크기와 위치를 보고 가격을 예측

---

### 2) 비지도학습 (Unsupervised Learning)

- **정답(Label)** 없이 **입력 데이터만**으로 학습한다.
- 목표는 **데이터 내 숨겨진 패턴이나 구조**를 찾아내는 것이다.
- 주로 **클러스터링(군집화)**, **차원 축소** 등의 작업에 활용된다.
- **예시**:  
  - 고객의 구매 패턴을 기반으로 유형 분류  
  - 고차원 데이터를 시각화를 위해 차원 축소

---

### 3) 반지도학습 (Semi-Supervised Learning)

- **라벨이 있는 데이터와 없는 데이터를 모두 사용**하여 학습한다.
- 현실에서는 대부분의 데이터가 라벨이 없고, 일부만 라벨이 있기 때문에 실용적이다.
- **지도학습의 정확도**와 **비지도학습의 범용성**을 결합한 방식이다.
- 단, 라벨이 없는 데이터를 잘못 사용하면 성능이 떨어질 수 있어 주의가 필요하다.
- **예시**:  
  - 소수의 라벨된 의료 이미지와 다량의 미라벨 이미지로 병리 진단 모델 학습

---

### 4) 강화학습 (Reinforcement Learning)

- **에이전트(Agent)** 가 **환경(Environment)** 과 상호작용하며 **보상(Reward)** 을 최대화하는 방향으로 학습한다.
- 에이전트는 상태를 관찰하고, 행동을 선택하고, 그 결과로 보상과 새로운 상태를 받는다.
- 목표는 **미래의 보상이 최대가 되도록 하는 최적의 정책(Policy)** 을 학습하는 것이다.
- **지도학습과 달리 정답이 명시적으로 존재하지 않으며**, 보상 신호만 존재한다.
- **예시**:  
  - 로봇이 장애물을 피하며 목적지까지 이동  
  - 게임 AI가 점수를 극대화하는 전략을 스스로 학습

---
### 학습 유형 정리

| 구분        | 정답(Label) | 목적                    | 대표 작업           | 예시                          |
|-------------|-------------|-------------------------|----------------------|-------------------------------|
| 지도학습    | 있음        | 정답 예측               | 분류, 회귀           | 고양이/개 분류, 가격 예측     |
| 비지도학습  | 없음        | 패턴/구조 발견           | 군집화, 차원 축소     | 고객 유형 분류, 시각화        |
| 반지도학습  | 일부 있음   | 소량 라벨 + 대량 무라벨 학습 | 분류, 예측           | 의료 이미지 진단              |
| 강화학습    | 없음 (보상만 존재) | 최적의 행동 학습        | 게임, 제어           | 자율 주행, 게임 AI            |

---
## 3️⃣ 머신러닝의 전체 파이프라인

머신러닝은 단순히 알고리즘만 적용하는 것이 아니라, 데이터 수집부터 평가까지 전체 흐름을 이해하고 다룰 수 있어야 한다. 수집된 데이터에는 **결측값(None)** 이나 **입력 크기 차이(예: 256x256 vs 32x32 이미지)** 같은 문제가 있을 수 있으므로, 전처리 과정이 필수적이다. 이후 사용할 특징(Feature)을 선택하고, 적절한 0모델을 선택한 뒤 학습을 수행한다. 학습된 모델은 예측 결과를 실제 정답과 비교해 성능을 평가하며, 이 과정에서 과적합을 방지하고 일반화 성능을 높이는 것이 중요하다.

```text
데이터 수집 → 전처리 → 특징 추출(선택) → 모델 선택 → 학습 → 예측 → 평가
```

---
### 1. 데이터 수집 (Data Collection)

모델이 학습할 수 있도록 **입력 데이터와 정답(Label)** 을 확보하는 단계이다.

- 예: CSV 파일, 센서 데이터, 웹 크롤링, 공공 데이터셋
- 유명한 공개 데이터셋 예시:
  - MNIST (손글씨 숫자 이미지)
  - Titanic (승객 생존 예측)
  - Iris (꽃 종류 분류)

---
### 2. 데이터 전처리 (Preprocessing)

수집된 데이터는 대부분 **결측치**, **이상치**, **범주형 변수**, **스케일 차이** 등의 문제를 안고 있다.  
모델이 잘 학습할 수 있도록 데이터를 정제하는 단계이다.

- 예:
  - 결측값 제거 또는 평균으로 채우기
  - 범주형 변수 → 원-핫 인코딩
  - 수치형 변수 정규화 (예: MinMaxScaler)

---
### 3. 특징 추출 및 선택 (Feature Engineering)

데이터에서 어떤 속성(Feature)을 사용할지 정의하는 단계이다.

- 머신러닝에서는 사람이 직접 특징을 정의해야 한다.
- 예:
  - "연령", "키", "몸무게" 같은 수치형 변수
  - "텍스트의 길이", "단어 수" 같은 파생 변수 생성

> 💡 딥러닝은 이 과정을 신경망이 자동으로 수행한다는 점에서 차이가 있다.

---
### 4. 모델 선택 (Model Selection)

문제의 종류(회귀, 분류 등)에 따라 어떤 알고리즘을 쓸지 선택하는 단계이다.

- 회귀 문제: 선형 회귀, 결정 트리 회귀, SVR 등
- 분류 문제: 로지스틱 회귀, Random Forest, SVM, KNN 등
- 교차 검증을 통해 여러 모델을 비교할 수도 있다.

---
### 5. 모델 학습 (Training)

학습 데이터를 이용해 **모델이 입력과 정답 사이의 관계를 학습**하도록 만드는 단계이다.

- 손실 함수(Loss)를 최소화하는 방향으로 파라미터를 조정한다.
- 에포크(Epoch), 배치 크기(Batch Size), 학습률(Learning Rate) 등의 하이퍼파라미터를 조절한다.

---
### 6. 예측 (Prediction)

학습된 모델을 사용하여 **새로운 입력에 대한 결과를 예측**하는 단계이다.

- 예:
  - 키와 몸무게를 입력하면 체질량지수(BMI)를 예측
  - 이메일 내용을 보고 스팸 여부 판단

---
### 7. 모델 평가 (Evaluation)

모델의 성능을 정량적으로 측정하는 단계이다.  
훈련 데이터에만 잘 맞고 실제 상황에서는 못 쓰는 모델은 **과적합(Overfitting)** 이라고 한다.

- 회귀 문제: MSE, RMSE, MAE
- 분류 문제: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-score
- 테스트셋을 따로 분리하여 성능을 확인하는 것이 일반적이다.

---

# 4️⃣ Feature와 Label 개념

머신러닝에서 가장 기본이 되는 개념 중 하나는 **입력값(Feature)** 과 **출력값(Label)** 이다. 모델은 데이터를 통해 **입력과 출력 간의 관계를 학습**하게 되므로, 이 두 요소를 명확하게 이해하는 것이 중요하다.

---
## Feature란?

- Feature(특징, 입력 변수)는 모델에 입력으로 주어지는 **설명 변수**이다.
- 일반적으로 **예측하고자 하는 대상에 영향을 줄 수 있는 정보들**로 구성된다.
- 수치형, 범주형, 텍스트, 이미지 등 다양한 형태가 가능하다.
### 예시

| 상황 | Feature (입력) | Label (출력) |
|------|----------------|---------------|
| 꽃 분류 | 꽃잎 길이, 꽃잎 너비 | 꽃의 품종 |
| 집값 예측 | 면적, 방 개수, 위치 | 집 가격 |
| 이메일 분석 | 본문 단어 수, 링크 개수 | 스팸 여부 |
| 손글씨 인식 | 이미지 픽셀 값 | 숫자(0~9) |

---
## Label이란?

- Label(정답, 목표값)은 **예측하고자 하는 대상**이다.
- 지도학습에서는 반드시 Feature와 함께 Label도 주어져야 한다.
- 문제 유형에 따라 Label의 형태도 달라진다.

| 문제 유형 | Label 예시 |
|-----------|------------|
| 분류(Classification) | 스팸 여부, 질병 유무, 이미지 속 객체 종류 |
| 회귀(Regression) | 가격, 온도, 수치 등 연속 값 |

---
## Feature와 Label 구분 시 주의점

Feature와 Label을 구분할 때 데이터셋 내에서 어떤 열이 정답처럼 보이더라도, 문제를 어떻게 정의하느냐에 따라 Feature와 Label은 달라질 수 있다. 

예를 들어 학생 성적 데이터가 있다고 가정하자. 이 데이터를 활용해 시험 점수를 예측하려는 경우에는 시험 점수가 Label이 된다. 하지만 반대로 시험 점수에 영향을 주는 요인을 분석하고자 한다면, 시험 점수는 오히려 Feature로 사용될 수 있다. 이처럼 문제 정의에 따라 입력과 출력의 위치가 바뀔 수 있음을 항상 염두에 두어야 한다.

---
## 딥러닝과의 차이점

머신러닝에서는 특징을 사람이 직접 설계해야 한다는 점이 큰 특징이다. 즉, 어떤 변수를 Feature로 사용할 것인지, 어떤 방식으로 데이터를 가공할 것인지 등을 사람이 지정해야 한다. 

반면, 딥러닝은 원시 데이터(Raw Data)를 그대로 모델에 입력으로 넣고, 신경망이 학습을 통해 중요한 특징을 스스로 추출해내는 방식이다. 이 차이로 인해 딥러닝은 전처리나 Feature Engineering 과정이 간단할 수 있지만, 더 많은 데이터와 계산 자원이 필요하다는 점도 함께 고려해야 한다.

---
## 5️⃣ 데이터셋 분리 – Train / Validation / Test

머신러닝에서 모델의 성능을 객관적으로 평가하고 일반화 능력을 높이기 위해, 전체 데이터를 **세 가지 용도**로 나누어 사용하는 것이 일반적이다.

| 구분 | 사용 시점 | 용도 | 특징 |
|------|-----------|------|------|
| 학습 데이터 | 모델 학습 중 | 입력-출력 관계 학습 | 직접 파라미터 조정 |
| 검증 데이터 | 학습 도중 | 성능 평가 및 하이퍼파라미터 튜닝 | 학습에는 미사용 |
| 테스트 데이터 | 학습 완료 후 | 최종 성능 평가 | 성능 일반화 지표 |

---
##  1. 학습 데이터 (Training Data)

- 모델을 **직접 학습시키는 데 사용되는 데이터**이다.
- 이 데이터를 바탕으로 모델은 **입력과 출력 간의 패턴**을 학습한다.
- 학습 데이터의 **양이 많고 다양할수록**, 모델이 더 잘 일반화될 가능성이 높다.
- 모델의 파라미터는 이 데이터를 기준으로 조정된다.
---
##  2. 검증 데이터 (Validation Data)

- 학습 도중 모델의 성능을 점검하고, **하이퍼파라미터를 조정**하는 데 사용된다.
- 예를 들어:
  - 학습률(Learning Rate)
  - 에포크(Epoch) 수
  - 최적화 알고리즘 등
- 검증 데이터는 **직접 학습에 사용되지 않으며**, 모델의 **성능을 간접적으로 추정**하는 데 쓰인다.
- 이 데이터를 통해 **과적합 여부를 판단**하고, **학습을 중지하는 시점(Early Stopping)** 도 결정할 수 있다.
---
##  3. 테스트 데이터 (Test Data)

- 모델이 완전히 학습을 마친 후, **최종 성능을 평가**하는 데 사용된다.
- 테스트 데이터는 **학습이나 검증에 한 번도 사용되지 않은 새로운 데이터**여야 한다.
- 모델이 실제 환경에서 얼마나 잘 예측하는지를 평가하기 위한 가장 중요한 기준이다.
- 테스트 데이터를 통해 얻은 성능 지표(정확도, RMSE 등)는 모델의 **최종 성능을 대표**하게 된다.

---
##  데이터 분할 비율

- 학습 데이터와 검증 데이터를 나눌 때는 일반적으로 **8:2 또는 7:3 비율**을 사용한다.
- **입력 데이터가 많을 경우**에는 7:3 비율로 나누어 검증 데이터도 넉넉하게 확보한다.
- 반면, **데이터가 적을 경우**에는 8:2로 설정하여 최대한 많은 데이터를 학습에 활용한다.

---
## 과적합과 부적합

### 과적합 (Overfitting)

- 모델이 학습 데이터에 **지나치게 잘 맞는 경우**로, 새로운 데이터에 대한 일반화 성능이 떨어진다.
- **학습 데이터 성능은 높지만, 테스트 성능은 낮은 경우** 발생한다.
- 너무 복잡한 모델 구조이거나, 학습 데이터에 비해 파라미터 수가 많거나, 검증 없이 오랫동안 학습한 경우 가 원인이 될 수 있다.
- 해결 방법으로는 검증 데이터 사용 (Early Stopping), Dropout, Regularization 등 규제 기법 활용, 더 많은 학습 데이터 확보 등의 방법이 있다.

### 부적합 (Underfitting)

- 모델이 학습 데이터조차 제대로 학습하지 못하는 경우이다.
- **학습 성능 자체가 낮고, 테스트 성능도 낮다.**
- 너무 단순한 모델이거나, 학습이 부족(에포크 수 적음)한 경우,  잘못된 Feature 선택한 경우에 발생한다.
- 해결 방법으로는 더 복잡한 모델 사용, 학습 시간 증가, Feature 재설계 등이 있다.


---
# 6️⃣ 모델 평가 지표 (Evaluation Metrics)

모델을 학습한 후에는 성능을 평가해야 하며, 문제 유형에 따라 평가 방식이 달라진다.  
머신러닝에서 주로 다루는 문제는 **분류(Classification)** 와 **회귀(Regression)** 두 가지로 나뉜다.

## 문제 유형 개요

### 분류 (Classification)
- **목표**: 입력에 대해 **정해진 클래스(범주)** 중 하나를 예측하는 것
- **예시**: 이메일이 스팸인지 아닌지 분류, 이미지가 고양이/개/사람 중 무엇인지 분류
- **출력**: 클래스 레이블 (예: 0, 1, 2…)

### 회귀 (Regression)
- **목표**: 입력에 대해 **연속적인 수치**를 예측하는 것
- **예시**: 집값 예측, 온도 예측, 판매량 예측
- **출력**: 연속적인 숫자 값 (예: 250.5, 13.7 등)

이제 문제 유형에 따라 어떤 지표를 사용해 성능을 평가하는지 살펴보자.

---
## 분류(Classification) 문제 – 주요 지표

| 지표 | 설명 | 특징 |
|------|------|------|
| **Accuracy** | 전체 예측 중에서 정답 비율 | 간단하지만 불균형 데이터에 취약 |
| **Precision** | Positive로 예측한 것 중 실제 Positive 비율 | False Positive를 줄이는 데 중요 |
| **Recall** | 실제 Positive 중에서 맞춘 비율 | False Negative를 줄이는 데 중요 |
| **F1-score** | Precision과 Recall의 조화 평균 | Precision과 Recall이 모두 중요할 때 사용 |
| **Confusion Matrix** | 예측과 실제값을 비교한 2x2 표 | TP, FP, FN, TN 확인 가능 |

- 혼동 행렬 (Confusion Matrix) : 혼동 행렬은 실제 정답과 모델이 예측한 결과를 비교하여, 모델이 얼마나 잘 분류했는지를 직관적으로 이해할 수 있도록 도와준다.

| 예측값 \ 실제값 | Positive (True) | Negative (False) |
|------------------|------------------|-------------------|
| **Positive (예측)** | **TP (True Positive)** | **FP (False Positive)** |
| **Negative (예측)** | **FN (False Negative)** | **TN (True Negative)** |
- **True Positive (TP)**  
  실제 정답이 Positive인 데이터를 모델이 **정확히 Positive로 예측**한 경우
- **True Negative (TN)**  
  실제 정답이 Negative인 데이터를 모델이 **정확히 Negative로 예측**한 경우
- **False Positive (FP)**  
  실제 정답은 Negative인데, 모델이 **잘못하여 Positive로 예측**한 경우 
- **False Negative (FN)**  
  실제 정답은 Positive인데, 모델이 **잘못하여 Negative로 예측**한 경우  

예를 들어, 암 환자를 판별하는 모델에서
- TP는 실제 환자를 암으로 예측한 것 (정답)
- FP는 건강한 사람을 암으로 잘못 예측한 것 (불필요한 치료 발생 가능)
- FN은 실제 환자를 정상으로 잘못 예측한 것 (치명적인 실수)
- TN은 정상인을 정상으로 예측한 것 (정답)

---
## 회귀(Regression) 문제 – 주요 지표

| 지표 | 설명 | 특징 |
|------|------|------|
| **MAE** (Mean Absolute Error) | 오차의 절댓값 평균 | 해석이 쉬움, 이상치에 덜 민감 |
| **MSE** (Mean Squared Error) | 오차의 제곱 평균 | 큰 오차에 민감, 학습 손실 함수로 자주 사용 |
| **RMSE** (Root Mean Squared Error) | MSE의 제곱근 | 단위가 입력과 동일, 이상치에 민감 |
| **R²** (R-squared) | 결정계수, 설명력 지표 (0~1) | 1에 가까울수록 좋은 모델 |

---
## 다양한 지표가 필요한 이유

- 하나의 지표만으로 모델 성능을 완벽히 설명할 수 없다.
- 예를 들어, 암 진단 모델에서 환자 100명 중 99명이 건강한 경우, **정확도(Accuracy)가 99%**여도 **환자 1명을 놓치면 큰 문제**가 발생할 수 있다.
- 이런 상황에서는 **Precision**, **Recall**, **F1-score** 등이 훨씬 더 중요한 역할을 한다.

---

# 7️⃣ scikit-learn 소개

scikit-learn이란?
- NumPy/SciPy 기반 **범용 머신러닝 라이브러리**
- **일관된 API**(`fit()`, `predict()`, `score()`)와 **풍부한 전처리·모델·평가** 도구 제공
- 대규모 딥러닝보다는 **클래식 ML**에 최적화 (CPU, 중소규모 데이터셋)

다음 명령어를 통하여 scikit-learn의 version을 확인해보자.

```python
import sklearn
print("scikit-learn version:", sklearn.__version__)
```

---
## scikit-learn 퀵 레퍼런스

scikit-learn은 Python 기반의 대표적인 머신러닝 라이브러리로, 다양한 전처리 도구와 알고리즘, 모델 평가 기법 등을 일관된 API로 제공한다. 아래는 scikit-learn의 주요 기능을 범주별로 정리한 표이다.

| 범주        | 대표 클래스                                                                                   | 설명                                                   |
|-------------|------------------------------------------------------------------------------------------|--------------------------------------------------------|
| **전처리**     | `StandardScaler`, `OneHotEncoder`, `PolynomialFeatures`                                      | 수치 정규화, 범주 인코딩, 다항 특성 생성 등 전처리 작업 수행               |
| **분류**      | `KNeighborsClassifier`, `SVC`, `RandomForestClassifier`, `LogisticRegression`                | 클래스 분류를 위한 다양한 지도학습 분류 모델                            |
| **회귀**      | `LinearRegression`, `SVR`, `RandomForestRegressor`                                           | 연속적인 수치 예측을 위한 지도학습 회귀 모델                            |
| **클러스터링** | `KMeans`, `DBSCAN`, `AgglomerativeClustering`                                                | 비지도학습 기반 데이터 군집화 알고리즘                                 |
| **차원 축소**  | `PCA`, `TSNE`, `TruncatedSVD`                                                                | 고차원 데이터를 저차원으로 투영하여 시각화 또는 노이즈 제거에 활용              |
| **모델 선택** | `train_test_split`, `GridSearchCV`, `cross_val_score`                                        | 데이터 분할, 교차 검증, 하이퍼파라미터 튜닝 등 모델 성능 향상 도구              |
| **평가지표**   | `accuracy_score`, `mean_squared_error`, `roc_auc_score`, `confusion_matrix`, `classification_report` | 분류/회귀 문제에서 모델 성능을 수치적으로 평가하기 위한 지표 모음               |

---
# 8️⃣ 실습: Iris 분류

Iris란 머신러닝에서 자주 사용되는 꽃 품종 분류용 예제 데이터셋을 말한다.

주요 특징은 다음과 같다.
- 총 150개 샘플 (각 품종당 50개)
- 4개의 특징(feature): 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비
- 3개의 클래스(target): [0: Setosa, 1: Versicolor, 2: Virginica]

---
Iris 데이터를 불러오기 위해 `scikit-learn`의 `datasets` 모듈에서 `load_iris` 함수를 불러온다. `load_iris()`는 붓꽃(Iris) 데이터셋을 로드하는 함수로, 이 데이터셋은 머신러닝에서 자주 사용되는 대표적인 분류용 예제 데이터이다. `load_iris(as_frame=True)`를 사용하면 데이터를 **pandas의 DataFrame 형태로 반환**해주므로, 이후 데이터 처리나 시각화 작업이 훨씬 수월해진다. 불러온 결과는 `iris`라는 변수에 저장되며, 여기에는 특징 데이터(`data`)와 정답 레이블(`target`)이 함께 포함되어 있다.

- `X = iris.data` : 꽃잎과 꽃받침의 길이/너비 정보를 담은 **입력 데이터(Feature)**
- `y = iris.target` : 해당 꽃이 어떤 품종인지 알려주는 **출력 데이터(Label)**

```python
from sklearn.datasets import load_iris
iris = load_iris(as_frame=True)
X, y = iris.data, iris.target
```
---
아래 코드는 전체 데이터를 학습용(train)과 테스트용(test)으로 나누는 과정이다.
`train_test_split` 함수를 사용해 `X`와 `y`를 각각 80%는 학습용(`X_train`, `y_train`), 20%는 테스트용(`X_test`, `y_test`)으로 분리한다.

- `stratify=y`는 클래스 비율이 학습/테스트에 동일하게 유지되도록 한다.
- `random_state=42`는 랜덤 분할 결과를 고정시켜, 실행할 때마다 동일한 결과가 나오게 한다.

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```
---
아래 코드는 **전처리와 모델을 하나의 파이프라인으로 연결**해주는 작업이다.
- `StandardScaler()`는 데이터를 정규화(평균 0, 표준편차 1)해주는 전처리 도구이다.
- `KNeighborsClassifier(n_neighbors=3)`는 KNN 분류 모델로, 주변 3개의 데이터를 기준으로 분류한다.
- `Pipeline`을 사용하면 전처리와 모델 학습을 연속적으로 수행할 수 있다.
- 마지막 `pipe.fit()`은 학습 데이터를 넣어 파이프라인 전체를 학습시킨다.

```python
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("knn",    KNeighborsClassifier(n_neighbors=3))
])
pipe.fit(X_train, y_train)
```

---
아래 코드는 **학습한 모델을 평가하는 단계**이다.
- `pipe.predict(X_test)`는 테스트 데이터를 이용해 예측 결과를 생성한다.
- `accuracy_score()`는 예측값과 실제값을 비교해 **정확도**를 계산한다.
- `classification_report()`는 정밀도, 재현율, F1-score 등의 지표를 출력한다.
- `confusion_matrix()`는 예측 결과와 실제 정답 간의 **혼동 행렬**을 보여준다.

```python
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
y_pred = pipe.predict(X_test)

print("정확도:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
```

--- 

이 코드는 **하이퍼파라미터 튜닝**을 위한 과정이다.
- `GridSearchCV`는 지정된 파라미터 범위(`n_neighbors`)에 대해 모델을 여러 번 학습하고 성능을 비교한다.
- `param_grid`는 `KNeighborsClassifier`의 이웃 수를 1, 3, 5, 7로 설정해 시도한다.
- `cv=5`는 5겹 교차검증을 수행하여 각 설정의 평균 성능을 평가한다.
- `grid.best_params_`는 성능이 가장 좋았던 파라미터 값을 출력한다.
- `grid.best_score_`는 해당 파라미터 조합에서의 평균 정확도를 보여준다.

```python
from sklearn.model_selection import GridSearchCV

param_grid = {"knn__n_neighbors": [1, 3, 5, 7]}
grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(X_train, y_train)

print("최적 파라미터:", grid.best_params_)
print("검증 정확도:", grid.best_score_)
```

---

# 9️⃣ 과제

참고) 필요 시 `!pip install scikit-learn -U`로 최신 버전 설치

> 데이터셋: `load_wine()` (와인 품질 데이터)
1. KNN 기본 정확도 측정
2. `test_size=0.3`으로 변경 후 정확도 비교
3. `n_neighbors`를 1, 3, 5로 바꾸며 각각 정확도 기록

### 힌트
```python
from sklearn.datasets import load_wine
from sklearn.metrics import accuracy_score

wine = load_wine(as_frame=True)
X_train, X_test, y_train, y_test = train_test_split(
    wine.data, wine.target,
    test_size=0.3, stratify=wine.target, random_state=42
)

for k in [1, 3, 5]:
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)
    acc = model.score(X_test, y_test)
    print(f"k={k}, 정확도={acc:.3f}")
```

> 추가 도전 
> • `StandardScaler`를 파이프라인에 넣고 성능 비교
> • `cross_val_score`로 평균 정확도 측정

---

